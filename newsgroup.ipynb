{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+S3v/roTUs82E6/4LrIBb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lyuyanyii/text-classification/blob/main/newsgroup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V6W6m5pdPKt",
        "outputId": "49c8924a-2052-42e2-c12f-75b04512c40c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.36371682]\n",
            " [-0.13497666]\n",
            " [-1.06752997]\n",
            " [ 0.65696306]\n",
            " [ 0.87770999]\n",
            " [ 1.47520152]\n",
            " [ 0.83228965]\n",
            " [ 0.24712302]\n",
            " [ 0.07981165]\n",
            " [-1.22591496]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "print(np.random.normal(loc = 0, scale = 1, size = (10, 1)))\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "os.system('wget https://github.com/lil-lab/lm-class/raw/refs/heads/main/assignments/a1/starter-repo/data/newsgroups/train/train_data.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.system('wget https://github.com/lil-lab/lm-class/raw/refs/heads/main/assignments/a1/starter-repo/data/newsgroups/train/train_labels.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMpukklYa9Cq",
        "outputId": "ae066eb0-17a3-400e-fd03-9c9c1548164f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import string\n",
        "\n",
        "D = 128\n",
        "\n",
        "def data_process(raw_text : string):\n",
        "    text = raw_text.lower()\n",
        "    raw_word_list = text.split()\n",
        "    word_list = []\n",
        "    for raw_word in raw_word_list:\n",
        "        word = ''.join([i for i in raw_word if i.isalpha()])\n",
        "        if word != '':\n",
        "            word_list.append(word)\n",
        "    return word_list\n",
        "\n",
        "def bag_of_words_embedding(word_vector_dict : dict, word_list : list):\n",
        "    vector_list = []\n",
        "\n",
        "    for word in word_list:\n",
        "        if word not in word_vector_dict:\n",
        "            word_vector_dict[word] = np.random.normal(loc = 0, scale = 0.5, size = (D, 1))\n",
        "\n",
        "        embedding = word_vector_dict[word]\n",
        "        vector_list.append(embedding)\n",
        "\n",
        "    bag_of_words = np.concatenate(vector_list, axis = 1).mean(axis = 1)\n",
        "    return bag_of_words\n",
        "\n",
        "train_data = []\n",
        "word_vector_dict = {}\n",
        "\n",
        "with open('train_data.csv', newline = '') as file:\n",
        "    csv_file = csv.DictReader(file)\n",
        "    for line in csv_file:\n",
        "        word_list = data_process(line['text'])\n",
        "\n",
        "        train_data.append(bag_of_words_embedding(word_vector_dict, word_list))\n",
        "\n",
        "print(len(train_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGfl94rwfAH8",
        "outputId": "10b9b876-edbd-4885-b373-36566af4a3f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = []\n",
        "label_index_map = {}\n",
        "\n",
        "num_class = 0\n",
        "\n",
        "with open('train_labels.csv', newline = '') as file:\n",
        "    csv_file = csv.DictReader(file)\n",
        "    for line in csv_file:\n",
        "        label = line['newsgroup']\n",
        "\n",
        "        if label not in label_index_map:\n",
        "            label_index_map[label] = num_class\n",
        "            num_class += 1\n",
        "\n",
        "        index = label_index_map[label]\n",
        "        train_labels.append(index)\n",
        "\n",
        "print(num_class)\n",
        "print(len(train_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJnrLn50iRxE",
        "outputId": "9301a615-e917-4f8e-bc69-39af9144313e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n",
            "9051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ratio = 0.8\n",
        "dataset_size = len(train_data)\n",
        "\n",
        "valid_data = train_data[ int(dataset_size * train_ratio) : ]\n",
        "valid_labels = train_labels[ int(dataset_size * train_ratio) : ]\n",
        "\n",
        "train_data = train_data[ : int(dataset_size * train_ratio) ]\n",
        "train_labels = train_labels[ : int(dataset_size * train_ratio) ]\n",
        "\n",
        "print(len(train_data))\n",
        "print(len(valid_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SddOeqd3lniy",
        "outputId": "57ca63d2-0541-47c2-a282-798979c24ab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7240\n",
            "1811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear:\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        self.w = np.random.normal(loc = 0, scale = 1 / in_dim**0.5, size = (out_dim, in_dim))\n",
        "        self.b = np.random.normal(loc = 0, scale = 1 / in_dim**0.5, size = (out_dim, 1))\n",
        "        self.grad_w = np.zeros((out_dim, in_dim))\n",
        "        self.grad_b = np.zeros((out_dim, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        self.out = np.matmul(self.w, x) + self.b\n",
        "        return self.out\n",
        "\n",
        "    def back_prop(self, grad_out):\n",
        "        self.grad_b = grad_out.mean(axis = 0)\n",
        "        self.grad_w = np.matmul(grad_out, self.x.transpose(0, 2, 1)).mean(axis = 0)\n",
        "        self.grad_x = np.matmul(self.w.transpose((1, 0)), grad_out)\n",
        "        return self.grad_x\n",
        "\n",
        "    def update(self, lr):\n",
        "        self.w += self.grad_w * lr\n",
        "        self.b += self.grad_b * lr\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPSPkyIMpO4_",
        "outputId": "f32981a8-c494-46a0-beb5-5b889366bbce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.01965774 0.1078472 ]\n",
            " [0.43081159 0.2941039 ]\n",
            " [0.3580904  0.64021895]]\n",
            "[[-0.90678279]\n",
            " [-0.13409614]\n",
            " [-0.61950386]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Relu:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.mask = (x >= 0)\n",
        "        return x * self.mask\n",
        "\n",
        "    def back_prop(self, grad_y):\n",
        "        return grad_y * self.mask\n"
      ],
      "metadata": {
        "id": "ASRyBfc00flJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Softmax:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        exp_x = np.exp(x)\n",
        "        d1, d2, d3 = x.shape\n",
        "        self.y = exp_x / exp_x.sum(axis = 1).reshape(d1, 1, 1)\n",
        "        return self.y\n",
        "\n",
        "    def back_prop(self, grad_y):\n",
        "        (d1, d2, d3) = grad_y.shape\n",
        "        # print((np.identity(d2) - self.y).shape)\n",
        "        # print((self.y.transpose(0, 2, 1)* (np.identity(d2, ) - self.y)).shape)\n",
        "        # print(self.y.transpose(0, 2, 1))\n",
        "        # print(self.y.transpose(0, 2, 1)* (np.identity(d2, ) - self.y))\n",
        "        grad_x = np.matmul( (self.y.transpose(0, 2, 1) * (np.identity(d2) - self.y)), grad_y )\n",
        "        return grad_x\n",
        "\n",
        "\"\"\"\n",
        "x = np.arange(0, 3)\n",
        "x = x.reshape((1, 3, 1))\n",
        "sft_layer = Softmax()\n",
        "y = sft_layer.forward(x)\n",
        "print(y)\n",
        "grad_y = np.array([1,0,0])\n",
        "grad_y = grad_y.reshape((1, 3, 1))\n",
        "grad_x = sft_layer.back_prop(grad_y)\n",
        "print(grad_x)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "ZAU3E9sN1acV",
        "outputId": "d457deb0-c401-4117-c6fc-13d7b58536e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nx = np.arange(0, 3)\\nx = x.reshape((1, 3, 1))\\nsft_layer = Softmax()\\ny = sft_layer.forward(x)\\nprint(y)\\ngrad_y = np.array([1,0,0])\\ngrad_y = grad_y.reshape((1, 3, 1))\\ngrad_x = sft_layer.back_prop(grad_y)\\nprint(grad_x)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "depth = 3\n",
        "\n",
        "network = []\n",
        "for i in range(depth - 1):\n",
        "    network.append((Linear(D, D), Relu()))\n",
        "network.append((Linear(D, num_class), Softmax()))\n",
        "\n",
        "def train(network, data, labels, lr):\n",
        "    x = np.vstack(data)\n",
        "    (d1, d2) = x.shape\n",
        "    x = x.reshape(d1, d2, 1)\n",
        "    for (layer, f_layer) in network:\n",
        "        x = f_layer.forward(layer.forward(x))\n",
        "\n",
        "    # loss1 = - np.log(np.vstack([x[i][labels[i]][0] for i in range(d1)]))\n",
        "    d1, d2, d3 = x.shape\n",
        "    loss = - np.log(x[range(d1), labels, 0]).mean()\n",
        "    grad_x = np.zeros((d1, d2, d3))\n",
        "    for i in range(d1):\n",
        "        grad_x[i, labels[i], 0] = 1/x[i, labels[i], 0]\n",
        "\n",
        "    for (layer, f_layer) in reversed(network):\n",
        "        grad_y1 = f_layer.back_prop(grad_x)\n",
        "        grad_y2 = layer.back_prop(grad_y1)\n",
        "        grad_x = grad_y2\n",
        "        layer.update(lr)\n",
        "\n",
        "    return loss\n",
        "\n",
        "def eval(network, data):\n",
        "    x = np.vstack(data)\n",
        "    (d1, d2) = x.shape\n",
        "    x = x.reshape(d1, d2, 1)\n",
        "    for (layer, f_layer) in network:\n",
        "        x = f_layer.forward(layer.forward(x))\n",
        "\n",
        "    d1, d2, d3 = x.shape\n",
        "    x = x.reshape(d1, d2)\n",
        "    idx = np.argmax(x, axis = 1)\n",
        "    return idx\n",
        "\n",
        "num_epochs = 30\n",
        "\n",
        "for i in range(num_epochs):\n",
        "    loss = 0\n",
        "    print('---- Epoch ', i, '----')\n",
        "    for j in range(len(train_data) // 10):\n",
        "        start = j * 10\n",
        "        end = min(start + 10, len(train_data))\n",
        "        loss = train(network, train_data[start:end], train_labels[start:end], lr = 0.1)\n",
        "    print('Loss = ', loss)\n",
        "\n",
        "    pred = eval(network, valid_data)\n",
        "    acc = np.array(pred == valid_labels).mean()\n",
        "    print('Validation Accurary = ', acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1G9mk2zG76a",
        "outputId": "f40b1270-88fa-4270-81fd-ad9ce4ac4662"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- Epoch  0 ----\n",
            "Loss =  2.865137022134048\n",
            "Validation Accurary =  0.10877967973495306\n",
            "---- Epoch  1 ----\n",
            "Loss =  2.334840964357313\n",
            "Validation Accurary =  0.12534511319712865\n",
            "---- Epoch  2 ----\n",
            "Loss =  2.0913923632225666\n",
            "Validation Accurary =  0.18056322473771397\n",
            "---- Epoch  3 ----\n",
            "Loss =  1.958881150471436\n",
            "Validation Accurary =  0.22418553285477635\n",
            "---- Epoch  4 ----\n",
            "Loss =  1.8752006602857514\n",
            "Validation Accurary =  0.26780784097183874\n",
            "---- Epoch  5 ----\n",
            "Loss =  1.7717380361872017\n",
            "Validation Accurary =  0.2992821645499724\n",
            "---- Epoch  6 ----\n",
            "Loss =  1.7076223340537815\n",
            "Validation Accurary =  0.315847598012148\n",
            "---- Epoch  7 ----\n",
            "Loss =  1.6897743487110666\n",
            "Validation Accurary =  0.34732192159028163\n",
            "---- Epoch  8 ----\n",
            "Loss =  1.6797477521370012\n",
            "Validation Accurary =  0.3556046383213694\n",
            "---- Epoch  9 ----\n",
            "Loss =  1.6576702734747386\n",
            "Validation Accurary =  0.36112644947542794\n",
            "---- Epoch  10 ----\n",
            "Loss =  1.6235430065094465\n",
            "Validation Accurary =  0.36664826062948647\n",
            "---- Epoch  11 ----\n",
            "Loss =  1.6144546373677493\n",
            "Validation Accurary =  0.37879624516841526\n",
            "---- Epoch  12 ----\n",
            "Loss =  1.579158649256191\n",
            "Validation Accurary =  0.37161789066813916\n",
            "---- Epoch  13 ----\n",
            "Loss =  1.5824745298537306\n",
            "Validation Accurary =  0.38100496963003866\n",
            "---- Epoch  14 ----\n",
            "Loss =  1.5413677010254268\n",
            "Validation Accurary =  0.38818332413031476\n",
            "---- Epoch  15 ----\n",
            "Loss =  1.554214075794612\n",
            "Validation Accurary =  0.39536167863059085\n",
            "---- Epoch  16 ----\n",
            "Loss =  1.547764901096392\n",
            "Validation Accurary =  0.39039204859193816\n",
            "---- Epoch  17 ----\n",
            "Loss =  1.5362134942642693\n",
            "Validation Accurary =  0.3837658752070679\n",
            "---- Epoch  18 ----\n",
            "Loss =  1.5108447789652384\n",
            "Validation Accurary =  0.3898398674765323\n",
            "---- Epoch  19 ----\n",
            "Loss =  1.4815718660162247\n",
            "Validation Accurary =  0.3920485919381557\n",
            "---- Epoch  20 ----\n",
            "Loss =  1.4311627103157134\n",
            "Validation Accurary =  0.38763114301490886\n",
            "---- Epoch  21 ----\n",
            "Loss =  1.3944533244517259\n",
            "Validation Accurary =  0.390944229707344\n",
            "---- Epoch  22 ----\n",
            "Loss =  1.3266295955045753\n",
            "Validation Accurary =  0.387078961899503\n",
            "---- Epoch  23 ----\n",
            "Loss =  1.2734446550334348\n",
            "Validation Accurary =  0.39260077305356156\n",
            "---- Epoch  24 ----\n",
            "Loss =  1.2300631434111406\n",
            "Validation Accurary =  0.390944229707344\n",
            "---- Epoch  25 ----\n",
            "Loss =  1.1888598721893473\n",
            "Validation Accurary =  0.387078961899503\n",
            "---- Epoch  26 ----\n",
            "Loss =  1.1426431139259516\n",
            "Validation Accurary =  0.3931529541689674\n",
            "---- Epoch  27 ----\n",
            "Loss =  1.149642698545166\n",
            "Validation Accurary =  0.3898398674765323\n",
            "---- Epoch  28 ----\n",
            "Loss =  1.0292172192126177\n",
            "Validation Accurary =  0.3920485919381557\n",
            "---- Epoch  29 ----\n",
            "Loss =  1.0121320247416203\n",
            "Validation Accurary =  0.39536167863059085\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SFZe8By_D997"
      }
    }
  ]
}